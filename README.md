# -RAG-LLM-
LLM 结合 RAG 技术可显著提升开发效率并缩短周期，优化提示词与知识库能最大化模型性能。不同模型可根据成本与速度需求选择。本研究验证了 LLM+RAG 在医疗领域的应用潜力，但知识库覆盖范围、模型泛化能力及长期维护仍需优化。未来将扩展知识库并提升智能化水平，以提供更精准的医疗辅助工具。
### 1：论文在解决什么问题?（why）
相较于传统数据收集，RAG+LLM大模型能在CKD上面提升多少效率(慢性肾脏病 (chronic kidney disease，CKD))

### 2：这件事为什么值得做？（Motivation）
1：现在这个CDK已成为全球公共健康领域面临的重大挑战之一，用AI给医疗知识管理提供全新路径
2：很多LLM模型已经成熟，可以来调用API接口帮助医生更好的了解患者的信息
### 3：作者用了什么方法？（What / How）
1：用Kimi，智谱，讯飞星火这三款LLM的大模型进行比对，在30个问题样例进行评分
2：用RAG+Ollama+MaxKB+Docker技术组件+检索功能判断Agent的回答是否正确
3：优化Prompt来减少LLM幻觉，调用的是Owen14b模型(硅基流动)
### 4：数据从哪来？（Data）
**知识库构建数据**：CKD医学指南，药品数据库、医院电子病历(脱敏)、文献；经预处理后用于RAG知识库
**模型评估数据**：30个研究者设计的CKD问题；10名临床药师评分(30份评分表)
**开发效率数据**：5家软件开发公司在4个阶段的实际时间记录(对比传统VS LLM+RAG模式)

### 5：实验怎么证明它有效？（Experiment）

本研究通过**双轨实验设计**证明模型的有效性
1. **轨道一：模型性能有效性（证明LLM+RAG在CKD场景下提升用药教育质量）**
2. **轨道二：开发效率有效性（证明LLM+RAG缩短开发周期、降低成本）**

| **验证目标** | **实验方法**                           | **关键证据**                           | **统计结果**        |
| -------- | ---------------------------------- | ---------------------------------- | --------------- |
| 模型性能有效性  | 专家评分（10名药师 × 30问题 × 3模型方式） + 5维度评估 | RAG集成后评分显著提升；Kimi+知识库最优；禁忌证识别准确率提高 | 双因素方差分析 P<0.001 |
| 开发效率有效性  | 5家公司时间日志对比（4阶段 × 2模式）              | 规则设计阶段省时80%；总时间缩短45.9%             | 配对t检验 P=0.017   |


### 6：这篇论文的「优点 & 局限」？（Strength & Limitation）
优点：
1：这篇论文不管是数据对比还有数据内容准确性很高，用的模型虽然不是顶尖的大模型，但是通过三款LLM大模型针对于30个问题进行比的结果来看谁的模型更胜一筹
2：很明显就能看出RAG大模型+LLM能够提升多少效率，并且比前几篇论文看起来更加严谨，过程的逻辑性也很强

局限：
1：人工审核样本量少(30个问题)
2：提示词设计的单一性未充分探索多模态输入的潜力
3：未评估系统在实际应用中的长期稳定性

### 7：对我有什么用？（Your Takeaway）
1：让我对RAG这个结构有更好的了解
2：智能体业务数据分析的框架有更加深入的理解
3：可以用千问大模型来连接'医脉通'(可以更加适合人医的最新治疗与指南)
<img width="1016" height="928" alt="image" src="https://github.com/user-attachments/assets/7e0be4ce-feb3-4526-bfd5-16ac9c6045bd" />
<img width="1051" height="843" alt="image" src="https://github.com/user-attachments/assets/8480bdf2-0553-4248-bd9f-2c0237954abc" />
